
# %% [markdown]
# LOADING THE DATASET

# %%
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc
from sklearn.model_selection import GridSearchCV
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the dataset (update with the correct file path)
df = pd.read_csv("training_set.csv")

# Show the first few rows of the dataset
df.head()




# %%
df.head()

# %% [markdown]
# HANDLING MISSING VALUES

# %%
# Fill missing LoanAmount with the median
df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)

# Fill missing Dependents with 0 (or drop rows if necessary)
df['Dependents'].fillna(0, inplace=True)

# Fill missing Self_Employed with the mode (most common category)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)

# Check if there are any missing values now
# Fill missing Gender with the most frequent value (mode)
df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)

# Fill missing Credit_History with the most frequent value (mode), assuming most customers have a good credit history
df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)

# Fill missing values for each column with appropriate strategies

# For categorical columns, use the mode (most frequent value)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Education'].fillna(df['Education'].mode()[0], inplace=True)
df['Loan_Status'].fillna(df['Loan_Status'].mode()[0], inplace=True)

# For numerical columns, use the median (to avoid outliers)
df['ApplicantIncome'].fillna(df['ApplicantIncome'].median(), inplace=True)
df['CoapplicantIncome'].fillna(df['CoapplicantIncome'].median(), inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)

# Verify that there are no missing values left
print(df.isnull().sum())
df.head()


# %% [markdown]
# PLOTTING THE DATA FOR INSIGHTS

# %%
df.head()

# %%


# %%
import matplotlib.pyplot as plt
import seaborn as sns

# Plot histogram for LoanAmount
sns.histplot(df['LoanAmount'], bins=20, kde=True)
plt.title('Distribution of Loan Amount')
plt.xlabel('Loan Amount')
plt.ylabel('Frequency')
plt.show()

# Plot histogram for ApplicantIncome
sns.histplot(df['ApplicantIncome'], bins=20, kde=True)
plt.title('Distribution of Applicant Income')
plt.xlabel('Applicant Income')
plt.ylabel('Frequency')
plt.show()

# Bar plot for categorical variables (e.g., Loan_Status)
sns.countplot(x='Loan_Status', data=df)
plt.title('Loan Status Distribution')
plt.show()

# Bar plot for property_Area
sns.countplot(x='property_Area', data=df)
plt.title('Property Area Distribution')
plt.show()


# %% [markdown]
# CORRELATION HEATMAP

# %%
df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})

# Exclude non-numeric columns before calculating correlation
numeric_df = df.select_dtypes(include=[np.number])

# Compute the correlation matrix for the numeric columns
corr_matrix = numeric_df.corr()

# Plot the correlation heatmap
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()


# %% [markdown]
# We find that credit hisotry has major influence on loan status

# %%
# Box plot to check for outliers in LoanAmount
sns.boxplot(x=df['LoanAmount'])
plt.title('Loan Amount Outliers')
plt.show()

# Box plot to check for outliers in ApplicantIncome
sns.boxplot(x=df['ApplicantIncome'])
plt.title('Applicant Income Outliers')
plt.show()


# %% [markdown]
# ENCODING TO CONVERT NON-NUMERICAL TO NUMERICAL DATA

# %%
df.head()

# %%
# Encoding categorical columns
df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})
df['Married'] = df['Married'].map({'Yes': 1, 'No': 0})
df['Education'] = df['Education'].map({'Graduate': 1, 'Not Graduate': 0})
df['Self_Employed'] = df['Self_Employed'].map({'Yes': 1, 'No': 0})
#df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})

# One-Hot Encoding for 'property_Area' column
df = pd.get_dummies(df, columns=['property_Area'], drop_first=True)
# Replace '3+' with 3 in the 'Dependents' column
df['Dependents'] = df['Dependents'].replace('3+', '3')

# Convert the 'Dependents' column to integer type
df['Dependents'] = df['Dependents'].astype(int)
# Check the transformed dataset
df.head()

# %%


# %%
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import joblib

# Features and target variable
X = df.drop(['Loan_ID', 'Loan_Status'], axis=1)
y = df['Loan_Status']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing the data (for models like SVM and Logistic Regression)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Defining the models
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(probability=True, random_state=42),  # Fixed: Added probability=True
    'Decision Tree': DecisionTreeClassifier()
}

# Evaluating each model
best_model = None
best_accuracy = 0

plt.figure(figsize=(8, 6))  # For ROC Curve plotting

for model_name, model in models.items():
    # Training the model
    model.fit(X_train_scaled, y_train)

    # Predicting the test set results
    y_pred = model.predict(X_test_scaled)

    # Calculating metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # For ROC AUC, use predict_proba if available
    if hasattr(model, "predict_proba"):
        y_proba = model.predict_proba(X_test_scaled)[:, 1]
    else:  # For models like SVC without predict_proba
        y_proba = model.decision_function(X_test_scaled)

    roc_auc = roc_auc_score(y_test, y_proba)

    print(f"Model: {model_name}")
    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1 Score: {f1}")
    print(f"ROC AUC: {roc_auc}")
    print("-" * 40)

    # Plot ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {roc_auc:.2f})")

    # Tracking the best model
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = model

# Plot ROC curves for all models
plt.plot([0, 1], [0, 1], linestyle='--', label='Random Model')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

# Save the best model
joblib.dump(best_model, 'best_loan_status_model.pkl')

print(f"The best model is: {best_model.__class__.__name__} with accuracy {best_accuracy}")


# %%
# Load the saved model
best_model = joblib.load('best_loan_status_model.pkl')

# Load the testing dataset
testing_set = pd.read_csv('testing_set.csv')

# Preprocess the testing dataset
# Ensure the testing dataset undergoes the same preprocessing as the training dataset
# 1. Encode categorical variables
testing_set['Gender'] = testing_set['Gender'].map({'Male': 1, 'Female': 0})
testing_set['Married'] = testing_set['Married'].map({'Yes': 1, 'No': 0})
testing_set['Education'] = testing_set['Education'].map({'Graduate': 1, 'Not Graduate': 0})
testing_set['Self_Employed'] = testing_set['Self_Employed'].map({'Yes': 1, 'No': 0})

# Handle columns with '3+' by replacing them with 3
# Handle columns with '3+' by replacing them with 3
# Handle columns with '3+' by replacing them with 3
if 'Dependents' in testing_set.columns:
    testing_set['Dependents'] = testing_set['Dependents'].replace({'3+': 3})  # Replace '3+' with 3
    testing_set['Dependents'] = testing_set['Dependents'].fillna(0)  # Fill NaN values with a default value, e.g., 0
    testing_set['Dependents'] = testing_set['Dependents'].astype(int)  # Convert to integer

# Handling missing values for other columns
for column in testing_set.columns:
    if testing_set[column].isnull().sum() > 0:
        # For numeric columns, fill missing values with the median
        if testing_set[column].dtype in ['float64', 'int64']:
            testing_set[column] = testing_set[column].fillna(testing_set[column].median())
        # For categorical columns, fill missing values with the mode
        else:
            testing_set[column] = testing_set[column].fillna(testing_set[column].mode()[0])


# One-hot encode the 'property_Area' column
testing_set = pd.get_dummies(testing_set, columns=['property_Area'], drop_first=True)

# Ensure the columns match the training data (align columns if necessary)
missing_cols = set(X.columns) - set(testing_set.columns)
for col in missing_cols:
    testing_set[col] = 0
testing_set = testing_set[X.columns]  # Align column order

# Standardize the features
scaler = StandardScaler()
testing_set_scaled = scaler.fit_transform(testing_set)

# Use the model to make predictions
predictions = best_model.predict(testing_set_scaled)

# Add predictions to the dataset
testing_set['Loan_Status_Predicted'] = predictions

# Convert predictions back to human-readable format if necessary
testing_set['Loan_Status_Predicted'] = testing_set['Loan_Status_Predicted'].map({1: 'Y', 0: 'N'})

# Save the results
testing_set.to_csv('testing_set_with_predictions.csv', index=False)

print("Predictions saved to 'testing_set_with_predictions.csv'.")

# %%
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import joblib

class LoanAmountPredictor:
    def __init__(self):
        self.models = {
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0),
            'Lasso Regression': Lasso(alpha=1.0),
            'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5),
            'Random Forest': RandomForestRegressor(n_estimators=50, min_samples_split=2, random_state=42)
        }
        self.trained_models = {}
        self.best_model = None
        self.best_model_name = None
        self.feature_columns = None

    def evaluate_model(self, model, X, y):
        """Evaluate model using leave-one-out cross validation for small datasets"""
        y_pred = model.predict(X)
        
        # Calculate metrics
        mae = mean_absolute_error(y, y_pred)
        mse = mean_squared_error(y, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y, y_pred)
        
        # Calculate residuals
        residuals = y - y_pred
        
        return {
            'MAE': mae,
            'MSE': mse,
            'RMSE': rmse,
            'R2': r2,
            'predictions': y_pred,
            'residuals': residuals
        }

    def plot_model_evaluation(self, y, metrics, model_name):
        """Create evaluation plots for a model"""
        predictions = metrics['predictions']
        residuals = metrics['residuals']
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Actual vs Predicted plot
        ax1.scatter(y, predictions, alpha=0.5)
        min_val = min(y.min(), predictions.min())
        max_val = max(y.max(), predictions.max())
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
        ax1.set_xlabel('Actual Loan Amount')
        ax1.set_ylabel('Predicted Loan Amount')
        ax1.set_title(f'{model_name}: Actual vs Predicted')
        
        # Residuals plot
        ax2.scatter(predictions, residuals, alpha=0.5)
        ax2.axhline(y=0, color='r', linestyle='--')
        ax2.set_xlabel('Predicted Loan Amount')
        ax2.set_ylabel('Residuals')
        ax2.set_title(f'{model_name}: Residuals Plot')
        
        plt.tight_layout()
        return fig

    def train_and_evaluate(self, X, y):
        """Train all models and evaluate them"""
        results = {}
        evaluation_plots = {}
        best_score = float('-inf')
        
        print("\nModel Performance Metrics:")
        print("-" * 50)
        
        for name, model in self.models.items():
            print(f"\nTraining and evaluating {name}...")
            
            # Train on full dataset due to small size
            model.fit(X, y)
            self.trained_models[name] = model
            
            # Evaluate the model
            metrics = self.evaluate_model(model, X, y)
            results[name] = metrics
            
            # Print metrics
            print(f"MAE: {metrics['MAE']:.2f}")
            print(f"MSE: {metrics['MSE']:.2f}")
            print(f"RMSE: {metrics['RMSE']:.2f}")
            print(f"R²: {metrics['R2']:.2f}")
            
            # Create evaluation plots
            evaluation_plots[name] = self.plot_model_evaluation(y, metrics, name)
            
            # Update best model
            current_score = metrics['R2'] - (metrics['RMSE'] / y.mean())
            if current_score > best_score:
                best_score = current_score
                self.best_model = model
                self.best_model_name = name
        
        print(f"\nBest Model: {self.best_model_name}")
        return results, evaluation_plots

    def save_model(self, path='best_loan_amount_model.joblib'):
        """Save the best model to disk"""
        if self.best_model is not None:
            model_info = {
                'model': self.best_model,
                'feature_columns': self.feature_columns,
                'model_name': self.best_model_name
            }
            joblib.dump(model_info, path)
            print(f"Best model ({self.best_model_name}) saved to {path}")
        else:
            print("Warning: No best model available to save.")

def main():
    # Load your preprocessed data
    data = df
    # Initialize predictor
    predictor = LoanAmountPredictor()
    
    # Prepare features and target
    data = data[data['Loan_Status'] == 1]
    X = data.drop(['LoanAmount', 'Loan_Status','Loan_ID'], axis=1)
    y = data['LoanAmount']
    predictor.feature_columns = X.columns.tolist()
    
    # Train and evaluate models
    results, evaluation_plots = predictor.train_and_evaluate(X, y)
    
    # Try to save the best model
    predictor.save_model()
    
    # Show plots
    plt.show()

if __name__ == "__main__":
    main()

# %%
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import joblib

class LoanTermPredictor:
    def __init__(self):
        self.models = {
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0),
            'Lasso Regression': Lasso(alpha=1.0),
            'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5),
            'Random Forest': RandomForestRegressor(n_estimators=50, min_samples_split=2, random_state=42)
        }
        self.trained_models = {}
        self.best_model = None
        self.best_model_name = None
        self.feature_columns = None

    def evaluate_model(self, model, X, y):
        """Evaluate model using leave-one-out cross validation for small datasets"""
        y_pred = model.predict(X)
        
        # Calculate metrics
        mae = mean_absolute_error(y, y_pred)
        mse = mean_squared_error(y, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y, y_pred)
        
        # Calculate residuals
        residuals = y - y_pred
        
        return {
            'MAE': mae,
            'MSE': mse,
            'RMSE': rmse,
            'R2': r2,
            'predictions': y_pred,
            'residuals': residuals
        }

    def plot_model_evaluation(self, y, metrics, model_name):
        """Create evaluation plots for a model"""
        predictions = metrics['predictions']
        residuals = metrics['residuals']
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Actual vs Predicted plot
        ax1.scatter(y, predictions, alpha=0.5)
        min_val = min(y.min(), predictions.min())
        max_val = max(y.max(), predictions.max())
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
        ax1.set_xlabel('Actual Term Amount')
        ax1.set_ylabel('Predicted Term Amount')
        ax1.set_title(f'{model_name}: Actual vs Predicted')
        
        # Residuals plot
        ax2.scatter(predictions, residuals, alpha=0.5)
        ax2.axhline(y=0, color='r', linestyle='--')
        ax2.set_xlabel('Predicted Loan Term')
        ax2.set_ylabel('Residuals')
        ax2.set_title(f'{model_name}: Residuals Plot')
        
        plt.tight_layout()
        return fig

    def train_and_evaluate(self, X, y):
        """Train all models and evaluate them"""
        results = {}
        evaluation_plots = {}
        best_score = float('-inf')
        
        print("\nModel Performance Metrics:")
        print("-" * 50)
        
        for name, model in self.models.items():
            print(f"\nTraining and evaluating {name}...")
            
            # Train on full dataset due to small size
            model.fit(X, y)
            self.trained_models[name] = model
            
            # Evaluate the model
            metrics = self.evaluate_model(model, X, y)
            results[name] = metrics
            
            # Print metrics
            print(f"MAE: {metrics['MAE']:.2f}")
            print(f"MSE: {metrics['MSE']:.2f}")
            print(f"RMSE: {metrics['RMSE']:.2f}")
            print(f"R²: {metrics['R2']:.2f}")
            
            # Create evaluation plots
            evaluation_plots[name] = self.plot_model_evaluation(y, metrics, name)
            
            # Update best model
            current_score = metrics['R2'] - (metrics['RMSE'] / y.mean())
            if current_score > best_score:
                best_score = current_score
                self.best_model = model
                self.best_model_name = name
        
        print(f"\nBest Model: {self.best_model_name}")
        return results, evaluation_plots

    def save_model(self, path='best_loan_term_model.joblib'):
        """Save the best model to disk"""
        if self.best_model is not None:
            model_info = {
                'model': self.best_model,
                'feature_columns': self.feature_columns,
                'model_name': self.best_model_name
            }
            joblib.dump(model_info, path)
            print(f"Best model ({self.best_model_name}) saved to {path}")
        else:
            print("Warning: No best model available to save.")

def main():
    # Load your preprocessed data
    data = df
    # Initialize predictor
    predictor = LoanTermPredictor()  # Corrected class name here
    
    # Prepare features and target
    data = data[data['Loan_Status'] == 1]
    X = data.drop(['Loan_Amount_Term', 'Loan_Status','Loan_ID'], axis=1)
    y = data['Loan_Amount_Term']
    predictor.feature_columns = X.columns.tolist()
    
    # Train and evaluate models
    results, evaluation_plots = predictor.train_and_evaluate(X, y)
    
    # Try to save the best model
    predictor.save_model()
    
    # Show plots
    plt.show()

if __name__ == "__main__":
    main()


# %%
import pandas as pd
import joblib

# Load the trained model
model_info = joblib.load('best_loan_amount_model.joblib')
best_model = model_info['model']

# Load the new dataset
test_data = pd.read_csv('testing_set_with_predictions.csv')

# Filter rows where Loan_Status_Predicted is "No"
test_data_no = test_data[test_data['Loan_Status_Predicted'] == 'N']

# Prepare the test data (drop unnecessary columns)
X_test = test_data_no.drop(['LoanAmount', 'Loan_Status_Predicted'], axis=1)

# Predict loan amounts using the model
predictions = best_model.predict(X_test)

# Add the predictions as a new column
test_data_no['Predicted_LoanAmount'] = predictions

# Save the new data with predictions to a new CSV file
test_data_no.to_csv('ineligible_loan_predictions.csv', index=False)

print("Predictions for ineligible applicants saved to ineligible_loan_predictions.csv")


# %%



